{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python exercises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# load the necessary data\n",
    "employees = pd.read_csv('./data/employees.csv', index_col=0)\n",
    "projects = pd.read_csv('./data/projects.csv', index_col=0)\n",
    "departments = pd.read_csv('./data/departments.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1\n",
    "\n",
    "**Topics covered:**\n",
    "- using lists and dictionaries\n",
    "- accessing data with loc and iloc\n",
    "\n",
    "**Task:**  \n",
    "Create a dictionary where each key is a dataset name and its value is the imported DataFrame. Use `loc` to display the details of the 10th to 12th employees and `iloc` to display the first 2 rows of the *projects* dataset.\n",
    "\n",
    "**Implementation:**  \n",
    "We use slicing to access the 10th to 12th employees with `loc` and `iloc` to access the first 2 projects. We also display the *departments* dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = {'employees': employees, 'projects': projects, 'departments': departments}\n",
    "\n",
    "print('Employees from 10th to 12th:', datasets['employees'].loc[10:12], sep='\\n')\n",
    "\n",
    "print('First 2 projects:', datasets['projects'].iloc[:2], sep='\\n')\n",
    "\n",
    "print('Departments:', datasets['departments'], sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2\n",
    "\n",
    "**Topics covered:**\n",
    "- modifying data\n",
    "- dealing with missing values\n",
    "- deleting columns and records\n",
    "\n",
    "**Task:**  \n",
    "In the employees dataset, the *ProjectsDone* column has some missing values. Fill these missing values with the average number of projects done by all employees. Delete any record where the salary is below 3k$. Lastly, remove the *Bonus* column.\n",
    "\n",
    "**Implementation:**  \n",
    "We use the `fillna` method to fill the missing values with the average (`mean`) of the *ProjectsDone* column. We then use reassignation combined with data filtering to remove the records with a salary below 3k$ and use the `drop` method to remove the *Bonus* column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('NA values in employees dataset before:', employees['ProjectsDone'].isna().sum())\n",
    "employees['ProjectsDone'].fillna(employees['ProjectsDone'].mean(), inplace=True)\n",
    "print('NA values in employees dataset after:', employees['ProjectsDone'].isna().sum(), sep='\\n')\n",
    "\n",
    "print('Number of employees before:', employees.shape[0])\n",
    "employees = employees[employees['Salary'] >= 4_000]\n",
    "print('Number of employees after:', employees.shape[0])\n",
    "\n",
    "print('Employees columns before:', employees.columns.values)\n",
    "print('Employees columns after:', employees.drop('Bonus', axis=1).columns.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3\n",
    "\n",
    "**Topics covered:**\n",
    "- processing datasets with merge/join\n",
    "- statistical processing, grouping, and aggregation.\n",
    "\n",
    "**Task:**  \n",
    "Merge the *employees* dataset with the *projects* dataset on the *ProjectID* to associate employees with their current projects. Using the merged dataset, calculate the average salary of employees by project title. Then, show the best employee for each bonus group based on his projects done.\n",
    "\n",
    "**Implementation:**  \n",
    "We use the `merge` method to merge the datasets on the *ProjectID* column. We then use the `groupby` method to group the data by *ProjectTitle* and calculate the average salary with the `mean` method. For the last part, we use the `groupby` method to group the data by *Bonus* and use the `idxmax` method withing an `apply` method to get the best employee who might need a raise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged dataframe:\n",
      "           Name  Salary  ProjectsDone  AssignedProjectID  Bonus  \\\n",
      "0   James Smith    9689           3.0                  4      1   \n",
      "1     Raj Patel    2872           4.0                  4      4   \n",
      "2  Amelia Brown    4761           1.0                  4      1   \n",
      "\n",
      "               Title   StartDate     EndDate  Budget  \n",
      "0  Compliance Review  2021-04-01  2021-08-29   63572  \n",
      "1  Compliance Review  2021-04-01  2021-08-29   63572  \n",
      "2  Compliance Review  2021-04-01  2021-08-29   63572  \n",
      "Average salary by project:\n",
      "Title\n",
      "Compliance Review     4994.00\n",
      "Data Analytics        5438.60\n",
      "Financial Planning    7644.75\n",
      "Name: Salary, dtype: float64\n",
      "Best employees:\n",
      "                 Name  Salary  ProjectsDone  AssignedProjectID  Bonus\n",
      "Bonus                                                                \n",
      "0        Mason Carter    4564           7.0                  8      0\n",
      "1            John Doe    2509           8.0                  2      1\n",
      "2          Mia Thomas    9591           9.0                  3      2\n",
      "3        Lucas Walker    5193           7.0                  1      3\n",
      "4      Julian Jackson    4545           9.0                  8      4\n"
     ]
    }
   ],
   "source": [
    "merged_df = pd.merge(employees, projects, left_on='AssignedProjectID', right_on='ProjectID', how='inner')\n",
    "print('Merged dataframe:', merged_df.head(3), sep='\\n')\n",
    "\n",
    "average_salary_by_project = merged_df.groupby('Title')['Salary'].mean()\n",
    "print('Average salary by project:', average_salary_by_project.head(3), sep='\\n')\n",
    "\n",
    "# show the best employee's name and his projects done for each bonus group based on his projects done.\n",
    "best_employees = employees.groupby('Bonus').apply(lambda x: x.loc[x['ProjectsDone'].idxmax()])\n",
    "print('Best employees:', best_employees, sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4\n",
    "\n",
    "**Topics covered:**\n",
    "- using group functions\n",
    "- defining and calling functions\n",
    "- using conditional structures.\n",
    "\n",
    "**Task:**  \n",
    "Write a function that takes any of the three datasets as input and returns a summary dictionary containing the number of rows, the mean salary (or max budget for departments), and the most common project title. Use conditional structures to handle differences between datasets.\n",
    "\n",
    "**Implementation:**  \n",
    "We define a function that takes a dataset as input and returns a dictionary with the summary statistics (`mean`, `mode`, `max`). We use conditional structures (`if` and `elif`) to handle the differences between datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'RowCount': 50, 'MeanSalary': 6089.38, 'MostCommonProject': 'Financial Planning'}\n",
      "{'RowCount': 10, 'MeanBudget': 57013.7, 'MostCommonTitle': 'Operational Improvement'}\n",
      "{'RowCount': 5, 'MaxBudget': 948010}\n"
     ]
    }
   ],
   "source": [
    "def dataset_summary(dataset_name, df):\n",
    "    summary = {}\n",
    "    if dataset_name == 'employees':\n",
    "        summary['RowCount'] = len(df)\n",
    "        summary['MeanSalary'] = df['Salary'].mean()\n",
    "        # most common project must have the name of the project, not the ID\n",
    "        summary['MostCommonProject'] = projects.loc[df['AssignedProjectID'].mode()[0], 'Title']\n",
    "    elif dataset_name == 'projects':\n",
    "        summary['RowCount'] = len(df)\n",
    "        summary['MeanBudget'] = df['Budget'].mean()\n",
    "        summary['MostCommonProject'] = df['Title'].mode()[0]\n",
    "    elif dataset_name == 'departments':\n",
    "        summary['RowCount'] = len(df)\n",
    "        summary['MaxBudget'] = df['Budget'].max()\n",
    "    else:\n",
    "        summary['Error'] = \"Dataset name not recognized.\"\n",
    "    return summary\n",
    "\n",
    "# Example usage:\n",
    "employees_summary = dataset_summary('employees', employees)\n",
    "projects_summary = dataset_summary('projects', projects)\n",
    "departments_summary = dataset_summary('departments', departments)\n",
    "\n",
    "print(employees_summary)\n",
    "print(projects_summary)\n",
    "print(departments_summary)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
